#!/usr/bin/env python3
"""
ç°¡å–®çš„æœ¬é€±æ•¸æ“šæ›´æ–°è…³æœ¬
åªæ›´æ–°æœ€æ–°ä¸€é€±çš„æ•¸æ“šï¼Œä¸é‡æ–°è™•ç†æ­·å²æ•¸æ“š
"""

import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from etl import CryptoStockETL

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class WeeklyUpdate:
    def __init__(self):
        self.etl = CryptoStockETL()
        self.base_dir = Path(__file__).parent
        self.data_dir = self.base_dir / "public" / "data"
        self.historical_file = self.data_dir / "complete_historical_baseline.json"
        
    def get_current_week_key(self):
        """å–å¾—æœ¬é€±çš„week key"""
        last_friday = self.etl.get_last_friday_close()
        year, week, _ = last_friday.isocalendar()
        return f"{year}-W{week:02d}", last_friday
        
    def load_existing_data(self):
        """è¼‰å…¥ç¾æœ‰æ­·å²æ•¸æ“š"""
        if self.historical_file.exists():
            with open(self.historical_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            "generated_at": datetime.now().isoformat(),
            "timezone": "Asia/Taipei", 
            "baseline_time": "16:00",
            "period": "",
            "data": {}
        }
        
    def update_current_week_only(self):
        """åªæ›´æ–°æœ¬é€±æ•¸æ“š"""
        week_key, last_friday = self.get_current_week_key()
        logger.info(f"æ›´æ–°æœ¬é€±æ•¸æ“š: {week_key} ({last_friday.strftime('%Y-%m-%d')})")
        
        # è¼‰å…¥ç¾æœ‰æ•¸æ“š
        historical_data = self.load_existing_data()
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰æœ¬é€±æ•¸æ“š
        if week_key in historical_data.get("data", {}):
            logger.info(f"æœ¬é€±æ•¸æ“š {week_key} å·²å­˜åœ¨ï¼Œå°‡æ›´æ–°")
        else:
            logger.info(f"æ–°å¢æœ¬é€±æ•¸æ“š {week_key}")
            
        # è¼‰å…¥holdingsé…ç½®
        holdings = self.etl.load_holdings()
        logger.info(f"è™•ç† {len(holdings)} å®¶å…¬å¸")
        
        # æ”¶é›†æœ¬é€±æ•¸æ“š
        companies = {}
        success_count = 0
        
        for ticker, holding_info in holdings.items():
            logger.info(f"è™•ç† {ticker}...")
            
            try:
                # ç²å–è‚¡åƒ¹æ•¸æ“š
                stock_data = self.etl.fetch_stock_data(ticker, last_friday)
                if not stock_data:
                    logger.warning(f"ç„¡æ³•ç²å– {ticker} è‚¡åƒ¹")
                    continue
                    
                # ç²å–å¹£åƒ¹æ•¸æ“š  
                crypto_data = self.etl.fetch_crypto_data(holding_info['coin_id'], last_friday)
                if not crypto_data:
                    logger.warning(f"ç„¡æ³•ç²å– {holding_info['coin_id']} å¹£åƒ¹")
                    continue
                    
                companies[ticker] = {
                    "company_name": holding_info.get('company_name', f"{ticker} Inc."),
                    "ticker_used": ticker,
                    "stock_price": stock_data['close'],
                    "coin": holding_info['coin'],
                    "coin_price": crypto_data['close'],
                    "coin_id": holding_info['coin_id']
                }
                
                success_count += 1
                logger.info(f"âœ… {ticker}: ${stock_data['close']:.2f}, {holding_info['coin']}: ${crypto_data['close']:.2f}")
                
            except Exception as e:
                logger.error(f"è™•ç† {ticker} æ™‚å‡ºéŒ¯: {e}")
                continue
                
        # åªæœ‰åœ¨ç²å¾—å®Œæ•´æ•¸æ“šæ™‚æ‰æ›´æ–°
        if success_count == len(holdings):
            # æ›´æ–°æœ¬é€±æ•¸æ“š
            historical_data["data"][week_key] = {
                "baseline_date": last_friday.strftime('%Y-%m-%d'),
                "week_start": f"{last_friday.strftime('%Y-%m-%d')}T16:00:00-04:00",
                "companies": companies
            }
            
            # æ›´æ–°å…ƒæ•¸æ“š
            historical_data["generated_at"] = datetime.now().isoformat()
            
            # æ›´æ–°æœŸé–“ç¯„åœ
            all_dates = [week_data["baseline_date"] for week_data in historical_data["data"].values()]
            if all_dates:
                all_dates.sort()
                historical_data["period"] = f"{all_dates[0]} - {all_dates[-1]}"
                
            # ä¿å­˜æ›´æ–°å¾Œçš„æ•¸æ“š
            with open(self.historical_file, 'w', encoding='utf-8') as f:
                json.dump(historical_data, f, indent=2, ensure_ascii=False)
                
            # ğŸ”¥ CRITICAL: ç”Ÿæˆå‰ç«¯éœ€è¦çš„ weekly_stats.json æ ¼å¼
            self.generate_weekly_stats_format(week_key, last_friday, companies, holdings)
                
            logger.info(f"ğŸ‰ æˆåŠŸæ›´æ–°æœ¬é€±æ•¸æ“š {week_key}")
            logger.info(f"ç¸½é€±æ•¸: {len(historical_data['data'])}")
            return True
            
        else:
            logger.warning(f"åªç²å–äº† {success_count}/{len(holdings)} å®¶å…¬å¸çš„æ•¸æ“šï¼Œä¸æ›´æ–°")
            return False
            
    def generate_weekly_stats_format(self, week_key, last_friday, companies, holdings):
        """ç”Ÿæˆå‰ç«¯éœ€è¦çš„ weekly_stats.json æ ¼å¼"""
        logger.info("ç”Ÿæˆå‰ç«¯æ•¸æ“šæ ¼å¼...")
        
        # è½‰æ›ç‚ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
        frontend_data = []
        
        for ticker, company_data in companies.items():
            holding_info = holdings[ticker]
            
            # è¨ˆç®—æŒæœ‰é‡ä½”æ¯” (ç°¡åŒ–è¨ˆç®—)
            supply_percent = holding_info.get('holding_qty', 0) / 1000000  # ç°¡åŒ–è¨ˆç®—
            
            frontend_data.append({
                "ticker": ticker,
                "company_name": company_data["company_name"],
                "stock_close": company_data["stock_price"],
                "stock_pct_change": 0,  # é€±æ›´æ–°æ™‚æš«æ™‚è¨­ç‚º0ï¼Œéœ€è¦æ­·å²æ¯”è¼ƒæ‰èƒ½è¨ˆç®—
                "coin": company_data["coin"],
                "coin_close": company_data["coin_price"],
                "coin_pct_change": 0,   # é€±æ›´æ–°æ™‚æš«æ™‚è¨­ç‚º0ï¼Œéœ€è¦æ­·å²æ¯”è¼ƒæ‰èƒ½è¨ˆç®—
                "holding_qty": holding_info.get('holding_qty', 0),
                "holding_pct_of_supply": supply_percent,
                "market_cap": 0  # æš«æ™‚è¨­ç‚º0
            })
        
        # ç”Ÿæˆé€±æœŸçµæŸæ—¥æœŸ (é€±äº”)
        week_end_str = last_friday.strftime('%Y-%m-%d')
        
        weekly_stats = {
            "week_end": week_end_str,
            "generated_at": datetime.now().isoformat(),
            "data": frontend_data
        }
        
        # ä¿å­˜åˆ°å‰ç«¯æ•¸æ“šæ–‡ä»¶
        weekly_file = self.data_dir / "weekly_stats.json"
        with open(weekly_file, 'w', encoding='utf-8') as f:
            json.dump(weekly_stats, f, indent=2, ensure_ascii=False)
            
        # ç”Ÿæˆæ‘˜è¦æ–‡ä»¶
        summary = {
            "last_updated": weekly_stats["generated_at"],
            "companies_count": len(frontend_data),
            "week_end": week_end_str
        }
        
        summary_file = self.data_dir / "summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
            
        logger.info(f"âœ… ç”Ÿæˆå‰ç«¯æ•¸æ“šæ–‡ä»¶: {weekly_file}")
        logger.info(f"âœ… ç”Ÿæˆæ‘˜è¦æ–‡ä»¶: {summary_file}")

def main():
    """ä¸»å‡½æ•¸"""
    logger.info("é–‹å§‹æœ¬é€±æ•¸æ“šæ›´æ–°...")
    
    updater = WeeklyUpdate()
    success = updater.update_current_week_only()
    
    if success:
        print("âœ… æœ¬é€±æ•¸æ“šæ›´æ–°æˆåŠŸï¼")
        return 0
    else:
        print("âŒ æœ¬é€±æ•¸æ“šæ›´æ–°å¤±æ•—")
        return 1

if __name__ == "__main__":
    exit(main())